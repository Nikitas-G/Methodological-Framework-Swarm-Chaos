import numpy as np
import pandas as pd
import json
import matplotlib.pyplot as plt
from scipy.stats import spearmanr
from scipy.linalg import eigvalsh
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from pathlib import Path
# 1. Feature Extraction from nuScenes JSON
def extract_urban_features(json_path):
    if not Path(json_path).exists():
        return []
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    node_map = {n['token']: (n['x'], n['y']) for n in data.get('node', [])}
    features = []
    
    for poly in data.get('polygon', []):
        nodes = [node_map[t] for t in poly['exterior_node_tokens'] if t in node_map]
        if len(nodes) < 4: continue
        
        coords = np.array(nodes)
        # Shoelace formula for Area
        area = 0.5 * np.abs(np.dot(coords[:,0], np.roll(coords[:,1], 1)) - np.dot(coords[:,1], np.roll(coords[:,0], 1)))
        n_count = len(nodes)
        ln_v = np.log(n_count + 1)
        w, h = np.max(coords[:,0]) - np.min(coords[:,0]), np.max(coords[:,1]) - np.min(coords[:,1])
        aspect = w / (h + 1e-6)
        conv = area / (w * h + 1e-6)
        
        features.append([area, n_count, ln_v, aspect, conv])
    return features
# 2. Mechanistic CADI Simulation
def compute_cadi_index(features):
    f_area, f_nodes, f_lognodes, f_aspect, f_conv = features
    n_agents = int(np.clip(f_nodes * 2 + 20, 15, 100))
    pos = np.random.rand(n_agents, 2) * (10.0 + np.sqrt(f_area)/100)
    
    l2_trace = []
    for _ in range(30):
        dist = np.sqrt(np.sum((pos[:, None, :] - pos[None, :, :])**2, axis=-1))
        adj = (dist < (8.0 + f_aspect)).astype(float)
        laplacian = np.diag(adj.sum(axis=1)) - adj
        try:
            val = eigvalsh(laplacian)[1] if n_agents > 1 else 0
        except: val = 0
        l2_trace.append(val)
        pos += np.random.randn(n_agents, 2) * (0.5 - f_conv * 0.4)
        
    stability = 1.0 / (1.0 + np.std(l2_trace) + 1e-6)
    return (0.4 * stability) + (0.4 * np.mean(l2_trace)) - (0.2 * (f_nodes/15))

# 3. Main Audit Execution
json_files = ["singapore-onenorth.json", "boston-seaport.json", "singapore-hollandvillage.json", "singapore-queenstown.json"]
data_list = []
for file in json_files:
    data_list.extend(extract_urban_features(file))

X = np.array(data_list)
# Sample 2000 for efficiency
indices = np.random.choice(len(X), 2000, replace=False)
X_sub = X[indices]
y = np.array([compute_cadi_index(feat) for feat in X_sub])
# 4. Model Benchmarking
X_train, X_test, y_train, y_test = train_test_split(X_sub, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s = scaler.transform(X_test)
# SVR Training
svr = SVR(kernel='rbf', C=10.0, epsilon=0.01).fit(X_train_s, y_train)
svr_r2 = r2_score(y_test, svr.predict(X_test_s))

# Random Forest Training
rf = RandomForestRegressor(n_estimators=50, random_state=42).fit(X_train, y_train)
rf_r2 = r2_score(y_test, rf.predict(X_test))
print(f"SVR R2 Score: {svr_r2:.4f}")
print(f"Random Forest R2 Score: {rf_r2:.4f}")
